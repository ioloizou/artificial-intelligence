{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS\n",
    "\n",
    "\n",
    "\n",
    "1.   For each model:\n",
    "\n",
    "*   What happens inside the fit function?\n",
    "*   What happens in the predict function?\n",
    "*   How is the chosen performance score computed?\n",
    "*   What criteria is being optimized?\n",
    "\n",
    "\n",
    "2.   For the **linear regression** example and keeping the size of the test set fixed, \n",
    "\n",
    "*   What is the effect on the (test) performance when we progressively increase the amount of training data? Try with a single feature at a time. Plot the score vs the number of training points and discuss. \n",
    "\n",
    "\n",
    "*   What is the effect of using other variables other than the  'bmi' during training?, try training and testing on other single features. Is it using more information always better? Progressively add new features to the data matrix. Plot the score vs the number of features\n",
    "\n",
    "3. Are the **Naive Bayes and the KNN Classifiers**  affected by scaling in the features? Use the ``standardScaler``\n",
    "from scikit learn ``from sklearn import preprocessing `` before the fit function and compare the results\n",
    "\n",
    "4. **Train/Test or Train/Val/Test** In the above examples, we have split each dataset into two subsets each. Are two subsets (train and test) enough for the three models (lin reg,  NaiveBayes,KNN,)? Answer for each model. Which models would benefit from having a validation set?\n",
    "\n",
    "5.   Repeat the KNN example, but splitting the dataset into three subsets(train,val,test). Progressively modify the hyperparameter k.  What is the best neighborhood size k?, what is the appropriate methodologogy to find this number? \n",
    "6.   How do we know if learning was really succesful (vs underfitting or overfitting?)\n",
    "\n",
    "8.   Naive Bayesian classifiers are probabilistic classifiers. How do we recover the probabilistic information associated to this model? What quantities can we recover?\n",
    "\n",
    "9.   For the **classification methods**:\n",
    "- Which are Discriminative? Generative?\n",
    "- Can the method deal with non-linearly separable data?\n",
    "- Is the method suitable for multiclass classification problems?\n",
    "\n",
    "\n",
    "\n",
    "**BONUS**\n",
    "Implement your own version of the three algorithms and compare the results to the built-in functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "**What happens inside the fit function of linear regression in scikit-learn?**\n",
    "\n",
    "The fit function of linear regression in scikit-learn uses the ordinary least squares (OLS) method to find the best-fit line to the data. OLS works by minimizing the sum of the squared residuals, which are the differences between the actual target values and the predicted target values.\n",
    "\n",
    "The following steps are performed inside the fit function:\n",
    "\n",
    "1. The mean and standard deviation of the input features are calculated.\n",
    "2. The input features are normalized by subtracting the mean and dividing by the standard deviation.\n",
    "3. A pseudoinverse of the input features is calculated.\n",
    "4. The model coefficients are calculated by multiplying the pseudoinverse of the input features by the target values.\n",
    "\n",
    "**What happens in the predict function of linear regression in scikit-learn?**\n",
    "\n",
    "The predict function of linear regression in scikit-learn takes as input a set of normalized input features and predicts the target values for those input features.\n",
    "\n",
    "The following steps are performed inside the predict function:\n",
    "\n",
    "1. The input features are multiplied by the model coefficients.\n",
    "2. The intercept is added to the product of the input features and the model coefficients.\n",
    "3. The predicted target values are returned.\n",
    "\n",
    "**How is the chosen performance score computed?**\n",
    "\n",
    "The chosen performance score for linear regression in scikit-learn is the coefficient of determination (R²). R² is a measure of how well the model explains the variance in the target variable.\n",
    "\n",
    "R² is calculated as follows:\n",
    "\n",
    "R² = 1 - (RSS / TSS)\n",
    "where:\n",
    "\n",
    "RSS is the residual sum of squares, which is the sum of the squared residuals.\n",
    "TSS is the total sum of squares, which is the sum of the squared deviations of the target variable from its mean.\n",
    "R² ranges from 0 to 1, with higher values indicating a better fit.\n",
    "\n",
    "**What criteria is being optimized?**\n",
    "\n",
    "The criteria being optimized in linear regression is the sum of the squared residuals. The fit function tries to find the model coefficients that minimize the sum of the squared residuals.\n",
    "\n",
    "This means that the model is trying to find the best-fit line to the data, where the best-fit line is the line that is closest to the actual data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "**What happens inside the fit function?**\n",
    "The fit function of Naive Bayes in scikit-learn calculates the prior probabilities of each class and the conditional probabilities of each feature value given each class.\n",
    "\n",
    "The prior probabilities of each class are calculated by counting the number of instances of each class in the training data and dividing by the total number of instances in the training data.\n",
    "\n",
    "The conditional probabilities of each feature value given each class are calculated using Bayes' theorem. Bayes' theorem states that the probability of event A happening given that event B has already happened is equal to the probability of event B happening given that event A has already happened times the probability of event A happening divided by the probability of event B happening.\n",
    "\n",
    "In the context of Naive Bayes, event A is a feature value and event B is a class. For example, the conditional probability of the feature value \"male\" given the class \"spam\" would be calculated as follows:\n",
    "\n",
    "P(feature=\"male\" | class=\"spam\") = P(class=\"spam\" | feature=\"male\") * P(feature=\"male\") / P(class=\"spam\")\n",
    "\n",
    "where:\n",
    "* P(feature=\"male\" | class=\"spam\") is the conditional probability of the feature value \"male\" given the class \"spam\".\n",
    "* P(class=\"spam\" | feature=\"male\") is the probability of the class \"spam\" given the feature value \"male\".\n",
    "* P(feature=\"male\") is the prior probability of the feature value \"male\".\n",
    "* P(class=\"spam\") is the prior probability of the class \"spam\".\n",
    "**What happens in the predict function?**\n",
    "The predict function of Naive Bayes in scikit-learn takes as input a set of feature values and predicts the most likely class for those feature values.\n",
    "\n",
    "The predict function works by calculating the posterior probability of each class given the feature values. The posterior probability of a class is the probability of that class happening given the feature values.\n",
    "\n",
    "The posterior probability of each class is calculated using Bayes' theorem. The predict function then returns the class with the highest posterior probability.\n",
    "**How is the chosen performance score computed?**\n",
    "The chosen performance score for Naive Bayes in scikit-learn is the accuracy. Accuracy is the percentage of instances that the model correctly predicts.\n",
    "\n",
    "Accuracy is calculated as follows:\n",
    "\n",
    "accuracy = (number of correct predictions) / (total number of predictions)\n",
    "**What criteria is being optimized?**\n",
    "\n",
    "The criteria being optimized in Naive Bayes is the maximum likelihood. Maximum likelihood means that the model is trying to find the parameters that maximize the probability of the training data.\n",
    "\n",
    "In Naive Bayes, the parameters are the prior probabilities of each class and the conditional probabilities of each feature value given each class.\n",
    "\n",
    "The fit function tries to find the values of these parameters that maximize the probability of the training data. This is done using an iterative algorithm called the expectation-maximization (EM) algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN classifiers\n",
    "\n",
    "**What happens inside the fit function?**\n",
    "The fit function of the KNN classifier in scikit-learn stores the training data in memory. This is necessary because the KNN classifier needs to compare new data points to all of the training data points to make predictions.\n",
    "\n",
    "The fit function also takes the following parameters:\n",
    "\n",
    "* n_neighbors: The number of neighbors to use when making predictions.\n",
    "* weights: A list of weights to assign to each neighbor. By default, all neighbors are given equal weight.\n",
    "* algorithm: The algorithm to use to find the nearest neighbors. The available algorithms are auto, ball_tree, kd_tree, and brute.\n",
    "\n",
    "**What happens in the predict function?**\n",
    "The predict function of the KNN classifier in scikit-learn takes a new data point as input and predicts the class of that data point.\n",
    "\n",
    "The predict function works by finding the K nearest neighbors of the new data point in the training data. The K nearest neighbors are the data points in the training data that are most similar to the new data point.\n",
    "\n",
    "Once the K nearest neighbors have been found, the KNN classifier predicts the class of the new data point by taking the majority vote of the K nearest neighbors.\n",
    "\n",
    "**How is the chosen performance score computed?**\n",
    "The chosen performance score for the KNN classifier in scikit-learn is the accuracy. Accuracy is the percentage of instances that the model correctly predicts.\n",
    "\n",
    "Accuracy is calculated as follows:\n",
    "\n",
    "accuracy = (number of correct predictions) / (total number of predictions)\n",
    "\n",
    "**What criteria is being optimized?**\n",
    "The criteria being optimized in the KNN classifier is the accuracy. The fit function does not optimize the accuracy directly, but it does store the training data in memory in a way that makes it efficient to find the nearest neighbors of new data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding part\n",
    "2.   For the **linear regression** example and keeping the size of the test set fixed, \n",
    "\n",
    "*   What is the effect on the (test) performance when we progressively increase the amount of training data? Try with a single feature at a time. Plot the score vs the number of training points and discuss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [938.23786125]\n",
      "Mean squared error: 2548.07\n",
      "Coefficient of determination: 0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes_X[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test, color=\"black\")\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color=\"blue\", linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
